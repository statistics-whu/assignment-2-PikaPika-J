---
title: "第二次作业"
author: "陈魏娟"
date: "2024-11-13"
output:   
  pdf_document: default
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
#load library
library(tidyverse) 
library(broom)
library(modelr)
library(stats)
library(lubridate)
library(kableExtra)
library(scales)
library(ggplot2)
library(e1071)
library(readxl)
library(carData)
library(gridExtra)
```

###Question #1The Big Bang Theory
#a. Compute the minimum and the maximum number of viewers.
```{r}
#读取数据
viewers <- read_csv("C:/Users/admin/Desktop/MEM/定量分析：商业统计/第二次作业/BigBangTheory.csv",
col_types = cols(
    `Air Date` = col_character(),
    `Viewers (millions)` = col_double()
  ))
#提取数据中对应列
viewers1 <- viewers %>%
  select(`Viewers (millions)`) %>% 
  pull()
#计算最小值和最大值
min_viewers <- min(viewers1,na.rm = TRUE)
max_viewers <- max(viewers1,na.rm = TRUE)
#输出结果
cat("The minimum number of viewers:", min_viewers)
cat("The maximum number of viewers:", max_viewers)

```

#b. Compute the mean, median, and mode.
```{r}
#计算均值，中位数
mean_viewers <- mean(viewers1, na.rm = TRUE)
median_viewers <- median(viewers1, na.rm = TRUE)
#计算众数
viewers2<-table(viewers1)
viewers3<-which.max(viewers2)
mode_viewers <- as.numeric(names(viewers2)[viewers3])
#输出结果
cat("The mean number of viewers:", mean_viewers, "\n")
cat("The median number of viewers:", median_viewers, "\n")
cat("The mode of the number of viewers:", mode_viewers, "\n")

```

#c. Compute the first and third quartiles.
```{r}
#计算四分位数
Q1 <- quantile(viewers1, probs = 0.25)
Q3 <- quantile(viewers1, probs = 0.75)
#输出结果
cat("the first quartile is:",Q1,"\n")
cat("the third quartile is:",Q3,"\n")
```

#d.has viewership grown or declined over the 2011–2012 season? Discuss.
```{r}
#读取数据
  viewers_a <- read_csv("C:/Users/admin/Desktop/MEM/定量分析：商业统计/第二次作业/BigBangTheory.csv",
  col_types = cols(`Air Date` = col_date(format = "%B %d, %Y"),  
                   `Viewers (millions)` = col_double()
    ))
#创建ggplot对象
  viewership_grown <- ggplot(data=viewers_a,aes(x = `Air Date` , y = `Viewers (millions)`)) +
    geom_point()+
    geom_line()+
    geom_smooth(method = "lm")
# 打印图表
  print(viewership_grown)
  
```
 

##Question #2:NBAPlayerPts.
#a. Show the frequency distribution.
```{r}
#读取数据
NBA_player <- read_csv("C:/Users/admin/Desktop/MEM/定量分析：商业统计/第二次作业/NBAPlayerPts.csv")
# 检查PPG列是否存在且没有NA值
if (!"PPG" %in% names(NBA_player) || any(is.na(NBA_player$PPG))) {
  stop("PPG don't have NA")
}
# 定义区间和标签
breaks <- seq(10, 30, by = 2)
# 分类PPG并创建频率表
classified_NBA <- cut(NBA_player$PPG, breaks = breaks, labels = c("10-11", "12-13", "14-15", "16-17", "18-19", "20-21", "22-24", "25-26", "27-28", "29-30"), include.lowest = TRUE)
NBA_freq_table <- table(classified_NBA)
# 将频率表转换为数据框并命名列
NBA_freq_df <- as.data.frame(NBA_freq_table)
colnames(NBA_freq_df) <- c("PPG_Range", "Frequency")
# 创建条形图
NBA_Freq <- ggplot(data = NBA_freq_df, aes(x = PPG_Range, y = Frequency)) +
  geom_histogram(stat = "identity") +
 labs(title = "Frequency Distribution of NBA Players' Points Per Game (PPG)",
       x = "Scoring range",
       y = "Frequency") 
# 打印图表
print(NBA_Freq)

```

#b. Show the relative frequency distribution.
```{r}
# 计算相对频率
NBA_relative_Fre <- NBA_freq_df$Frequency / sum(NBA_freq_df$Frequency)
# 绘制条形图
NBA_relative_Fre_bar <- ggplot(data = NBA_freq_df, aes(x = PPG_Range, y = NBA_relative_Fre)) +
  geom_bar(stat = "identity") +
  labs(title = "Frequency Distribution of NBA Players' Points Per Game (PPG)",
       x = "Scoring range",
       y = "Relative frequency") +
  scale_y_continuous(labels = scales::percent_format()) # 使用百分比格式显示y轴标签
# 显示图形
print(NBA_relative_Fre_bar)

```

#c. Show the cumulative percent frequency distribution.
```{r}
breaks <- c(10)
# 分类 PPG 值
classified_NBA1<- cut(NBA_player$PPG, breaks = breaks, labels = c("10-12", "10-14", "10-16", "10-18", "10-20", "10-22", "10-24", "10-26", "10-28", "10-30"), include.lowest = TRUE)
# 创建频率表
NBA_freq_table1 <- table(classified_NBA1)
# 转换为数据框
NBA_freq_df1 <- as.data.frame(NBA_freq_table1)
colnames(NBA_freq_df1) <- c("PPG_Range", "Frequency")
# 计算累计频率和累计百分比
NBA_freq_df1 <- NBA_freq_df1 %>%
  mutate(cumulative_Frequency = cumsum(Frequency),
         cumulative_Percent = cumulative_Frequency / sum(Frequency) )
#  绘制累计百分频率分布图
NBA_cumulative_Fre_bar <- ggplot(data = NBA_freq_df1, aes(x = PPG_Range, y = cumulative_Percent)) +
  geom_bar(stat = "identity",fill="blue") +
  labs(title = "Cumulative Percentage Frequency Distribution of NBA Players' Points Per Game",
       x = "Scoring range",
       y = "Cumulative percentage frequency")+
  scale_y_continuous(labels = scales::percent_format()) # 使用百分比格式显示y轴标签
# 显示图形
print(NBA_cumulative_Fre_bar)
```

#d. Develop a histogram for the average number of points scored per game.
```{r}
# 绘制直方图
ggplot(NBA_player, aes(x = PPG)) +
  geom_histogram(binwidth = 1, fill = "blue", color = "black") +
  labs(title = "Histogram of NBA players' average points per game (PPG).",
       x = "Average Points Per Game (PPG)",
       y = "Number of players") +
  theme_minimal()
```


e. Do the data appear to be skewed? Explain.
```{r}
# 计算NBA_player$PPG的偏度值
skewness_value <- skewness(summary(NBA_player $ PPG))
# 输出偏度值
cat("Skewness value：", skewness_value, "\n")
# 判断数据的对称性
if (abs(skewness_value) > 0.5) {
  cat("The data appears to be skewed.\n")
} else {
  cat("The data appears to be symmetrical.\n")
}
```

#f. What percentage of the players averaged at least 20 points per game?
```{r}
# 从NBA_player数据框中筛选出PPG大于或等于20的球员
players_num <- NBA_player[ NBA_player$PPG >= 20,]
# 计算场均得分至少为20分的球员数量
players_20 <- nrow( players_num )
# 计算NBA_player数据框中所有球员的数量
players_all<- nrow( NBA_player )
# 计算并输出场均得分至少为20分的球员所占的百分比，保留两位小数
cat(" The percentage of the players averaged at least 20 points per game：", round(players_20/players_all*100, 2), "%\n")

```

##Question #3: A researcher reports survey results by stating that the standard error of the mean is 20. The population standard deviation is 500.
#a. How large was the sample used in this survey?
```{r}
A <- 20
B <- 500
n <- (B / A)^2
print(n)
```
#b. What is the probability that the point estimate was within ±25 of the population mean?
```{r}
line1 <- -25 / A
line2 <- 25 / A
# 使用标准正态分布的累积分布函数计算line2对应的概率值减去line1对应的概率值
C <- pnorm(line2) - pnorm(line1)
print(C)
```


##Question #4: Young Professional magazine.
#a. Develop appropriate descriptive statistics to summarize the data.
```{r}
# 读取数据并重命名列
Professinal <- read_csv("C:/Users/admin/Desktop/MEM/定量分析：商业统计/第二次作业/Professional.csv")%>%
 rename( age = Age,
         gender = `Gender`,
    real_estate = `Real Estate Purchases?`,
    investments = `Value of Investments ($)`,
    num_trans = `Number of Transactions`,
    has_broadband = `Broadband Access?`,
    income = `Household Income ($)`,
    have_children = `Have Children?`) %>% 
  select(age:have_children) %>% 
  mutate(across(where(is.character), as.factor))
# 生成数据的摘要
skimr::skim(Professinal) %>% 
  kable() %>% 
  kable_styling()

```

#b. Develop 95% confidence intervals for the mean age and household income of subscribers.
```{r}
# 计算均值和标准差
Professinal_sum <- Professinal %>%
  summarise(
    MeanAge = mean(age, na.rm = TRUE),
    SDAge = sd(age, na.rm = TRUE),
    MeanHouseholdIncome = mean(income, na.rm = TRUE),
    SDHouseholdIncome = sd(income, na.rm = TRUE)
  )
print(Professinal_sum)
# 计算95%置信区间
Age1 <- with(Professinal, t.test(age)$conf.int)
Household_income1 <- with(Professinal, t.test(income)$conf.int)
# 打印置信区间
cat("95% confidence interval for the mean age:\n", Age1, "\n")
cat("95% confidence interval for the mean household income:\n", Household_income1, "\n")
```

#c. Develop 95% confidence intervals for the proportion of subscribers who have broadband access at home and the proportion of subscribers who have children.
```{r}
# 计算拥有宽带访问和有孩子的比例
broadband_access <- mean(Professinal$has_broadband == "Yes")
children_have <- mean(Professinal$have_children == "Yes")
# 计算95%置信区间
broadband1 <- prop.test(sum(Professinal$has_broadband == "Yes"), nrow(Professinal), conf.level = 0.95)$conf.int
children1 <- prop.test(sum(Professinal$have_children == "Yes"), nrow(Professinal), conf.level = 0.95)$conf.int
# 打印置信区间
cat("95% Confidence Interval for Broadband Access Proportion:", broadband1, "\n")
cat("95% Confidence Interval for Having Children Proportion:", children1, "\n")

```

#d. Would Young Professional be a good advertising outlet for online brokers? Justify your conclusion with statistical data.
```{r}
young_professionals <- subset(Professinal, age >= 25 & age <= 40)
young_professionals$has_broadband <- as.numeric(young_professionals$has_broadband == "Yes")
young_professionals$have_children <- as.numeric(young_professionals$have_children == "Yes")
broadband2 <- mean(young_professionals$has_broadband)
children2 <- mean(young_professionals$have_children)
if (broadband2 > 0.4 & children2 > 0.4) {
  cat("According to statistical data, the young professional demographic has a high proportion of broadband access and a significant percentage of individuals with children, making them a potentially favorable audience for online brokerage advertisements.\n")
} else {
  cat("According to statistical data, the young professional demographic may not have a sufficiently high proportion of broadband access or individuals with children. Further analysis or consideration of other factors is needed to determine their suitability as an advertising audience.\n")
}

```

#e. Would this magazine be a good place to advertise for companies selling educational software and computer games for young children?
Based on the known information that subscribers have a relatively low average age and a high proportion of them have young children, it can be inferred that this magazine targeted at young professionals is likely an appropriate advertising platform. Since these subscribers, as young parents or guardians, may have a relatively high demand for educational software and computer games for children, the answer is affirmative: this magazine is indeed a good advertising venue for companies selling educational software and computer games for young children.

#f. Comment on the types of articles you believe would be of interest to readers of Young Professional.
The reader base of "Young Professionals" primarily consists of young professionals who typically possess high educational backgrounds, professional qualities, and aspirations for a better life. Based on the characteristics of this group, the following is an analysis of the types of articles they may find interesting: career development, technology and innovation, investment and financial management, lifestyle and health, as well as family and parenting.

##Question #5:Quality Associate, Inc.
#a. Conduct a hypothesis test for each sample at the .01 level of significance and determine what action, if any, should be taken. Provide the p-value for each test.
```{r}
#读取数据
Quality <- read_csv("C:/Users/admin/Desktop/MEM/定量分析：商业统计/第二次作业/Quality.csv")
#转换为矩阵
Quality1 <- as.matrix(Quality)
#计算平均值
Quality_mean <- mean(Quality1)
#t检验
results <- list()
for (i in 1:ncol(Quality1)) {
  Quality2 <- Quality1[, i]
 t_test <- t.test(Quality2, mu = Quality_mean)
  results[[i]] <- list(
    p_value = t_test$p.value,
    action = ifelse(t_test$p.value < 0.01, "Take action", "Take no action")
  )
}
#显示结果
for (i in 1:length(results)) {
  cat("Sample", i, ":\n")
  cat("p-value:", results[[i]]$p_value, "\n")
  cat("Action:", results[[i]]$action, "\n\n")
}
```

#b. compute the standard deviation for each of the four samples. does the assumption of .21 for the population standard deviation appear reasonable?
```{r}
#计算标准差
sd_sample1 <- sd(Quality$`Sample 1`)
sd_sample2 <- sd(Quality$`Sample 2`)
sd_sample3 <- sd(Quality$`Sample 3`)
sd_sample4 <- sd(Quality$`Sample 4`)
#输出结果
cat("Standard deviation of Sample 1:", sd_sample1, "\n")
cat("Standard deviation of Sample 2:", sd_sample2, "\n")
cat("Standard deviation of Sample 3:", sd_sample3, "\n")
cat("Standard deviation of Sample 4:", sd_sample4, "\n")
```
The standard deviation is not significantly different from 0.21, suggesting that the hypothesis may be reasonable.

#c. compute limits for the sample mean x― around μ=12 such that, as long as a new sample mean is within those limits, the process will be considered to be operating satisfactorily. if x― exceeds the upper limit or if x― is below the lower limit, corrective action will be taken. these limits are referred to as upper and lower control limits for quality control purposes.
```{r}
# 计算样本量
n <- length(Quality)
# 转换为矩阵
Quality1 <- as.matrix(Quality)
# 计算均值和标准差
x_bar <- mean(Quality1)
sigma <- sd(Quality1)
# 设置显著性水平和给定的均值
alpha <- 0.05
mu <- 12
# 计算z值
z <- qnorm(1 - alpha/2)  
sigma <- sd(Quality1)
# 计算控制上限和下限
UCL <- mu + z * sigma / sqrt(n)
LCL <- mu - z * sigma / sqrt(n)
# 输出控制限
control_limits <- c(LCL, UCL)
print(control_limits)

```


#d.discuss the implications of changing the level of significance to a larger value. what mistake or error could increase if the level of significance is increased?
An increase in the probability of a Type I error (false positive) leads to a more lenient threshold for rejecting the null hypothesis (H₀). This makes the statistical test more sensitive to subtle differences in the sample data. It may imply that we are more willing to bear the risk of rejecting the null hypothesis, resulting in a decrease in our confidence in the outcome.

##Question #6:Occupancy
#a. Estimate the proportion of units rented during the first week of March 2007 and the first week of March 2008.
```{r}
# 读取数据
Occupancy <- read_csv("C:/Users/admin/Desktop/MEM/定量分析：商业统计/第二次作业/Occupancy.csv",skip=1)%>% 
# 重命名列
rename(mar_2007 = `March 2007`, mar_2008 = `March 2008`) %>% 
# 类型转换 
mutate(across(is.character,as.factor))
# 计算比例
week_2007 <- sum(Occupancy$mar_2007 == "Yes") / length(Occupancy$mar_2007)
week_2008 <- sum(Occupancy$mar_2008 %in% c("Yes"))/150
# 输出结果
print(week_2007)
print(week_2008)
```

#b. Provide a 95% confidence interval for the difference in proportions.
```{r}
confidence_week <- qnorm(0.975) * sqrt(week_2007*(1-week_2007)/200 + week_2008*(1-week_2008)/150)
print(confidence_week)
```

#c. On the basis of your findings, does it appear March rental rates for 2008 will be up from those a year earlier?
Yes, the interval does not contain zero, which indicates that we should reject the null hypothesis (i.e., the hypothesis that there is no significant difference in rental rates between the two periods). In statistics, if the confidence interval for the difference between two proportions does not contain zero, we generally consider these two proportions to be statistically significantly different. Therefore, based on the result of this confidence interval, we can infer that rental rates in March 2008 have increased compared to those a year earlier.

##Question #7Air Force Training Program 
#a. use appropriate descriptive statistics to summarize the training time data for each method. what similarities or differences do you observe from the sample data?
```{r}
Training <- read_csv("C:/Users/admin/Desktop/MEM/定量分析：商业统计/第二次作业/Training.csv")
skimr::skim(Training) %>% 
  kable() %>% 
  kable_styling()
```


#b. Comment on any difference between the population means for the two methods. Discuss your findings.
```{r}
t.test(Training$Current,Training$Proposed)

```

#c. compute the standard deviation and variance for each training method. conduct a hypothesis test about the equality of population variances for the two training methods. Discuss your findings.
```{r}
map(Training,sd)
map(Training,var)
var.test(Training$Current,Training$Proposed)
```

#d. what conclusion can you reach about any differences between the two methods? what is your recommendation? explain.
It can only reflect the central tendency of a dataset, but cannot provide information about the degree of dispersion of the data.Standard deviation and variance can provide important information about the degree of dispersion of the data. A larger standard deviation indicates greater differences between data points and the mean; a larger variance indicates a greater degree of deviation of data points from the mean.

#e. can you suggest other data or testing that might be desirable before making a final decision on the training program to be used in the future?
To determine whether the two programs offer similar or differing amounts of learning, such analysis should be conducted prior to making the final decision to adopt the proposed method. Additionally, gathering user preferences and experiences is also crucial.

##Question #8: The Toyota Camry 
#a. Develop a scatter diagram with the car mileage on the horizontal axis and the price on the vertical axis.
```{r}
# 读取数据并重命名
Camry <- read_csv("C:/Users/admin/Desktop/MEM/定量分析：商业统计/第二次作业/Camry.csv") %>%
  rename(miles = `Miles (1000s)`,
         price = `Price ($1000s)`)
# 绘制可视图
  Camry %>% 
  ggplot() +
  geom_point(aes(miles,price))
```

#b. what does the scatter diagram developed in part (a) indicate about the relationship between the two variables?
The relationship between the two variables can be approximated by a straight line that slopes downwards, indicating a negative correlation as the points on the scatter plot roughly follow this downward-sloping line.

#c. Develop the estimated regression equation that could be used to predict the price ($1000s) given the miles (1000s).
```{r}
lm_camry <- lm(price ~ miles, data = Camry)
summary(lm_camry)
```

#d. Test for a significant relationship at the .05 level of significance.
```{r}
Camry1 <- cor.test(Camry$miles, Camry$price)
print(Camry1)

```

#e. Did the estimated regression equation provide a good fit? Explain.
The estimated regression equation provides a statistically significant fit, explaining over half of the price variation, and the model parameters are also statistically significant.

#f. Provide an interpretation for the slope of the estimated regression equation.
The slope represents the average expected change in the dependent variable when the independent variable increases by one unit. If the slope is positive, there exists a positive correlation between the two variables. If the slope is negative, it indicates a negative correlation between the two variables. The larger the absolute value of the slope, the greater the average change in the dependent variable for each unit increase in the independent variable.

#g. Suppose that you are considering purchasing a previously owned 2007 Camry that has been driven 60,000 miles. Using the estimated regression equation developed in part (c), predict the price for this car. Is this the price you would offer the seller.
The predicted price for a 2007 Camry with 60,000 miles, based on the regression equation, is \ $17,617，while $17,617 is a useful estimate based on mileage, you should consider these additional factors before making an offer to the seller. It may be wise to conduct further research, inspect the car thoroughly, and negotiate based on all relevant information.

##Question #9:
#a. 通过可视化探索流失客户与非流失客户的行为特点（或特点对比），你能发现流失与非流失客户行为在哪些指标有可能存在显著不同？
```{r}
#读取数据
WE <- read_excel("C:/Users/admin/Desktop/MEM/定量分析：商业统计/第二次作业/WE.xlsx")
  plot_boxplot <- function(data, x_var, y_var) {
  ggplot(data, aes_string(x = factor(x_var), y = y_var)) + 
    geom_boxplot() +
    labs(title = paste("Boxplot of", y_var, "by", x_var),
         x = x_var,
         y = y_var)
  }
plot_list <- list(
  plot_boxplot(WE, "流失", "当月客户幸福指数"),
  plot_boxplot(WE, "流失", "当月服务优先级"),
  plot_boxplot(WE, "流失", "客户使用期限")
)
grid.arrange(grobs = plot_list, ncol = 2) 

```

b. 通过均值比较的方式验证上述不同是否显著。
```{r}
# 当月客户幸福指数的均值检验
t.test(当月客户幸福指数 ~ 流失, data = WE)
#p-value = 2.097e-13，p值远小于0.05，流失客户和非流失客户的当月客户幸福指数存在显著差异。95%置信区间：[18.79956,31.86737]。这个区间不包含0，进一步支持了两组均值不相等的结论。
# 客户幸福指数的均值检验
t.test(当月服务优先级 ~ 流失, data = WE)
#p-value = 4.381e-07，p值远小于0.05，流失客户和非流失客户的当月服务优先级存在显著差异。
#客户使用期限的均值检验
t.test(客户使用期限 ~ 流失, data = WE)
#p-value = 0.003057，p值远小于0.05，流失客户和非流失客户的客户使用期限存在显著差异


```

c. 以”流失“为因变量，其他你认为重要的变量为自变量（提示：a、b两步的发现），建立回归方程对是否流失进行预测。
```{r}
# 选择变量作为自变量
model <- glm(流失 ~ 当月客户幸福指数 + 当月服务优先级 + 客户使用期限, family = binomial(), data = WE)
summary(model)

```

d. 根据上一步预测的结果，对尚未流失（流失=0）的客户进行流失可能性排序，并给出流失可能性最大的前100名用户ID列表。
```{r}
# 筛选出尚未流失的客户
data_non_churn <- WE %>% filter(流失 == 1)

# 预测尚未流失的客户流失可能性
predictions <- predict(model, newdata = data_non_churn, type = "response")

# 将预测结果添加到筛选后的数据框中
data_non_churn$predictions <- predictions

# 对尚未流失的客户进行排序
sorted_customers <- data.frame(客户ID = data_non_churn$客户ID, 流失概率 = data_non_churn$predictions) %>%
  arrange(desc(流失概率))

# 提取前100名客户的ID
top_100_ids <- sorted_customers %>% head(100) %>% select(客户ID)

# 查看前100名客户的ID列表
print(top_100_ids)

```
